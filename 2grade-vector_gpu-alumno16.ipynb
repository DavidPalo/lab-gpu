{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92dd336-9997-4323-80e4-f285e9cc2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "8.44 ms ± 97 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.4 ms ± 34.3 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.4 ms ± 27 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbcd970-8e60-4ce8-b602-b70e8151e050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo GPU (copiando arrays CPU→GPU): 5.406 ms\n",
      "Tiempo GPU (arrays generados directamente en GPU): 4.835 ms\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Librerías\n",
    "# ==============================\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# ==============================\n",
    "# Función para la operación\n",
    "# ==============================\n",
    "def grade2_ufunc_cupy(x, y, a, b, c):\n",
    "    # x, y ya deben estar en GPU\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# ==============================\n",
    "# Parámetros\n",
    "# ==============================\n",
    "size = 5_000_000\n",
    "a_val = 3.5\n",
    "b_val = 2.8\n",
    "c_val = 10\n",
    "\n",
    "# ==============================\n",
    "# Caso 1: Copiando arrays desde CPU a GPU\n",
    "# ==============================\n",
    "# Arrays en CPU\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "\n",
    "# Copiamos a GPU\n",
    "a_gpu = cp.asarray(a_cpu)\n",
    "b_gpu = cp.asarray(b_cpu)\n",
    "\n",
    "# Benchmark\n",
    "t_copy = benchmark(grade2_ufunc_cupy, \n",
    "                   (a_gpu, b_gpu, a_val, b_val, c_val), \n",
    "                   n_repeat=5)\n",
    "gpu_avg_time_copy = np.average(t_copy.gpu_times) * 1e3  # ms\n",
    "print(f\"Tiempo GPU (copiando arrays CPU→GPU): {gpu_avg_time_copy:.3f} ms\")\n",
    "\n",
    "# ==============================\n",
    "# Caso 2: Arrays generados directamente en GPU\n",
    "# ==============================\n",
    "a_gpu_direct = cp.random.rand(size)\n",
    "b_gpu_direct = cp.random.rand(size)\n",
    "\n",
    "# Benchmark\n",
    "t_direct = benchmark(grade2_ufunc_cupy, \n",
    "                     (a_gpu_direct, b_gpu_direct, a_val, b_val, c_val), \n",
    "                     n_repeat=5)\n",
    "gpu_avg_time_direct = np.average(t_direct.gpu_times) * 1e3  # ms\n",
    "print(f\"Tiempo GPU (arrays generados directamente en GPU): {gpu_avg_time_direct:.3f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bcb200-78c0-4dd1-b053-9442f2d2cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo GPU Numba (copia automática CPU→GPU): 19.504 ms\n",
      "Tiempo GPU Numba (arrays ya en GPU): 2.367 ms\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Librerías\n",
    "# ==============================\n",
    "import numpy as np\n",
    "from numba import vectorize, float64\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# ==============================\n",
    "# Función con Numba en GPU\n",
    "# ==============================\n",
    "@vectorize([float64(float64, float64, float64, float64, float64)], target='cuda')\n",
    "def grade2_numba(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# ==============================\n",
    "# Parámetros\n",
    "# ==============================\n",
    "size = 5_000_000\n",
    "a_val = 3.5\n",
    "b_val = 2.8\n",
    "c_val = 10\n",
    "\n",
    "# ==============================\n",
    "# Caso 1: Copia automática de CPU a GPU\n",
    "# ==============================\n",
    "# Arrays en CPU\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "\n",
    "# Benchmark (Numba copia automáticamente los arrays a GPU)\n",
    "t_auto = benchmark(grade2_numba, (a_cpu, b_cpu, a_val, b_val, c_val), n_repeat=5)\n",
    "gpu_avg_time_auto = np.average(t_auto.gpu_times) * 1e3\n",
    "print(f\"Tiempo GPU Numba (copia automática CPU→GPU): {gpu_avg_time_auto:.3f} ms\")\n",
    "\n",
    "# ==============================\n",
    "# Caso 2: Arrays ya en GPU (sin contar la copia)\n",
    "# ==============================\n",
    "# Copiamos manualmente a GPU usando CuPy\n",
    "a_gpu = cp.asarray(a_cpu)\n",
    "b_gpu = cp.asarray(b_cpu)\n",
    "\n",
    "# Convertimos los arrays de CuPy a Numba device array\n",
    "from numba import cuda\n",
    "a_device = cuda.as_cuda_array(a_gpu)\n",
    "b_device = cuda.as_cuda_array(b_gpu)\n",
    "\n",
    "# Benchmark con arrays ya en GPU\n",
    "t_direct = benchmark(grade2_numba, (a_device, b_device, a_val, b_val, c_val), n_repeat=5)\n",
    "gpu_avg_time_direct = np.average(t_direct.gpu_times) * 1e3\n",
    "print(f\"Tiempo GPU Numba (arrays ya en GPU): {gpu_avg_time_direct:.3f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732a347-0b20-42c8-bce3-0a23b4689923",
   "metadata": {},
   "source": [
    "### Explicación: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8847b56-3a5f-47f5-8e1c-d27743cb24e9",
   "metadata": {},
   "source": [
    "Como podemos comprobar, el tiempo que se tarda es menor en si el array se crea directamente en la GPU que si lo pasamos de la CPU a la GPU.\n",
    "Este incremento se debe al tiempo necesario para transferir los datos desde la memoria de la CPU a la GPU. Al generar los datos directamente en la GPU (por ejemplo, usando CuPy), se evita esta transferencia, lo que permite ahorrar ese tiempo.\n",
    "\n",
    "Al comparar CuPy con Numba vemos que obtenemos un mayor rendimiento con esta última, sin embargo al pasar los arrays de CPU a GPu está mejor optimizado CuPy.\n",
    "\n",
    "Observando los resultados podemos comprobar que el tiempo que se tarda en pasar un array de la memoria de la CPU a la GPU puede legar a formar un cuello de botella elevado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
